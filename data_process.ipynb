{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "imdb = load_dataset(\"imdb\")\n",
    "\n",
    "train_dataset=imdb['train']\n",
    "test_dataset=imdb['test']\n",
    "\n",
    "train_X=train_dataset['text']\n",
    "train_Y=train_dataset['label']\n",
    "test_X=test_dataset['text']\n",
    "test_Y=test_dataset['label']\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "def preprocess(s):\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "    s = re.sub(r\"\\s+\", '', s)\n",
    "    s = re.sub(r\"\\d\", '', s)\n",
    "    return s\n",
    "\n",
    "def tockenize(train_X,test_X, vocab_size):\n",
    "    word_list = []\n",
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    for sent in train_X:\n",
    "        for word in sent.lower().split():\n",
    "            word = preprocess(word)\n",
    "            if word not in stop_words and word != '':\n",
    "                word_list.append(word)\n",
    "  \n",
    "    counted_word_list = Counter(word_list)\n",
    "\n",
    "    sorted_word_list= sorted(counted_word_list,key=counted_word_list.get,reverse=True)[:vocab_size-1]\n",
    "\n",
    "    vocab = {w:i+1 for i,w in enumerate(sorted_word_list)}\n",
    "    \n",
    "    # tockenize\n",
    "    final_list_train,final_list_test = [],[]\n",
    "    for sent in train_X:\n",
    "        final_list_train.append([vocab[preprocess(word)] for word in sent.lower().split() if preprocess(word) in vocab.keys()])\n",
    "    for sent in test_X:\n",
    "        final_list_test.append([vocab[preprocess(word)] for word in sent.lower().split()  if preprocess(word) in vocab.keys()])\n",
    "            \n",
    "\n",
    "    return np.array(final_list_train, dtype=object), np.array(final_list_test, dtype=object), vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=1000\n",
    "train_X, test_X, vocab = tockenize(train_X, test_X, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of vocabulary is {len(vocab)+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=500\n",
    "train_X_pad = padding_(train_X,seq_len)\n",
    "test_X_pad = padding_(test_X,seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f'vocab_{vocab_size}.json', 'w') as file:\n",
    "    json.dump(vocab, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'train_X_pad.txt', train_X_pad, fmt='%d')\n",
    "np.savetxt(f'test_X_pad.txt', test_X_pad, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'train_Y.txt', train_Y, fmt='%d')\n",
    "np.savetxt(f'test_Y.txt', test_Y, fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
